package com.slh.flutter_hw_live.push;import android.Manifest;import android.app.Activity;import android.app.AlertDialog;import android.app.Application;import android.app.Dialog;import android.content.Context;import android.graphics.SurfaceTexture;import android.opengl.GLES11Ext;import android.opengl.GLES20;import android.opengl.GLSurfaceView;import android.opengl.Matrix;import android.os.Bundle;import android.os.Handler;import android.text.TextUtils;import android.util.Log;import android.view.SurfaceView;import android.view.View;import android.view.animation.AlphaAnimation;import android.widget.RelativeLayout;import android.widget.Toast;import androidx.annotation.NonNull;import com.github.faucamp.simplertmp.RtmpHandler;import com.huawei.publishsdk.HwEncodeHandler;import com.huawei.publishsdk.HwPublisher;import com.huawei.publishsdk.HwRecordHandler;import com.meicam.sdk.NvsCaptureVideoFx;import com.meicam.sdk.NvsFxDescription;import com.meicam.sdk.NvsSize;import com.meicam.sdk.NvsStreamingContext;import com.slh.flutter_hw_live.NetworkUtils.NetworkUtils;import java.io.IOException;import java.net.SocketException;import java.nio.ByteBuffer;import java.nio.ByteOrder;import java.nio.FloatBuffer;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.Locale;import java.util.Map;import javax.microedition.khronos.egl.EGLConfig;import javax.microedition.khronos.opengles.GL10;import io.flutter.plugin.common.BinaryMessenger;import io.flutter.plugin.common.MethodCall;import io.flutter.plugin.common.MethodChannel;import io.flutter.plugin.platform.PlatformView;import static com.huawei.publishsdk.HwPublisher.RGBA;import static com.slh.flutter_hw_live.NetworkUtils.NetworkUtils.isAvailableByPing;public class HwPushView implements NvsStreamingContext.CaptureDeviceCallback,        SurfaceTexture.OnFrameAvailableListener, GLSurfaceView.Renderer,        RtmpHandler.RtmpListener,        HwEncodeHandler.HwEncodeListener,        HwRecordHandler.HwRecordListener,        NvsStreamingContext.CaptureRecordingDurationCallback,        NvsStreamingContext.CaptureRecordingStartedCallback, PlatformView, MethodChannel.MethodCallHandler {    private static final String TAG = "HwPushView";    private String rtmpUrl = "";    public static final String BEAUTY_SHAPE_EYE_ENLARGING = "Eye Enlarging";    public static final String BEAUTY_SHAPE_CHECK_THINNING = "Cheek Thinning";    public static final String BEAUTY_SHAPE_INTENSITY_FORHEAD = "Intensity Forhead";    public static final String BEAUTY_SHAPE_INTENSITY_CHIN = "Intensity Chin";    public static final String BEAUTY_SHAPE_INTENSITY_NOSE = "Intensity Nose";    public static final String BEAUTY_SHAPE_INTENSITY_MOUTH = "Intensity Mouth";    private static final double NORMAL_VELUE_INTENSITY_FORHEAD = 0.5;    private static final double NORMAL_VELUE_INTENSITY_CHIN = 0.5;    private static final double NORMAL_VELUE_INTENSITY_MOUTH = 0.5;    private static final int REQUEST_CAMERA_PERMISSION_CODE = 0;    private static final int REQUEST_RECORD_AUDIO_PERMISSION_CODE = 1;    private static final int REQUEST_WRITE_EXTERNAL_STORAGE_PERMISSION_CODE = 2;    public static final int CAPTURE_TYPE_ZOOM = 2;    public static final int CAPTURE_TYPE_EXPOSE = 3;    private static final int REQUEST_FILTER_LIST_CODE = 110;    private static final int ARFACE_LIST_REQUES_CODE = 111;    /**     * 权限检测器     */    private PermissionsChecker mPermissionsChecker;    private NvsStreamingContext mStreamingContext;//    private LinearLayout mFunctionButtonLayout;//    private LinearLayout mSwitchFacingLayout;//    private LinearLayout mSwitchEncoderLayout;//    private LinearLayout mFlashLayout;//    private ImageView mFlashButton;//    private LinearLayout mZoomLayout;//    private LinearLayout mExposureLayout;//    private LinearLayout mBeautyLayout;//    private LinearLayout mFilterLayout;//    private LinearLayout mFuLayout;//    private TextView mOk;    /**     * 推流的输入框     *///    private EditText rtmpUrlEdit;//    private TextView mSeekTitle;//    private TextView mSeekProgress;//    private ImageView mImageAutoFocusRect;    private boolean isPause;    //private PushNvAssetManager mAssetManager;    private boolean mPermissionGranted = true;    List<String> mAllRequestPermission = new ArrayList<>();    private Dialog mBuilderPermission;    private RelativeLayout mPermissionDialog;    private boolean mIsSwitchingCamera = false;    NvsStreamingContext.CaptureDeviceCapability mCapability = null;    private AlphaAnimation mFocusAnimation;    /**     * 变焦以及曝光dialog     */    private AlertDialog mCaptureZoomAndExposeDialog;    //    private View mZoomView;//    private SeekBar mZoomSeekbar;//    private SeekBar mExposeSeekbar;    private int mZoomValue;    private int mMinExpose;    private int mCaptureType;    /**     * 美颜Dialog     *///    private AlertDialog mCaptureBeautyDialog;//    private View mBeautyView;//    private Button mBeauty;//    private Button mBeautyShape;//    private RelativeLayout mBeautySelect;//    private RelativeLayout mBeautyShapeSelect;    /**     * 美颜     *///    private ImageView mSharpeningivClose;//    private ImageView mSharpeningIvOpen;//    private Switch mBeautySwitch;//    private TextView mBeautySwitchText;//    private SeekBar mStrength;//    private SeekBar mWhitening;//    private SeekBar mReddening;    private Boolean mIsBeautyType = true;    /**     * 美型     *///    private Switch mBeautyShapeSwitch;//    private TextView mBeautyShapeSwitchText;//    private SeekBar mLevel;//    private LinearLayout mBeautyShapeResetLayout;//    private ImageView mBeautyShapeResetIcon;//    private TextView mBeautyShapeResetTxt;//    private RecyclerView mBeautyShapeRecyclerView;//    private ShapeAdapter mShapeAdapter;    private String mCurBeautyShapeId = BEAUTY_SHAPE_CHECK_THINNING;    /**     * 美颜特效     */    private NvsCaptureVideoFx mBeautyFx;    private double mStrengthValue;    private double mWhiteningValue;    private double mReddeningValue;    private double mLevelValue = 0;    /**     * 滤镜     */    private int mFilterSelPos = 0;    private NvsCaptureVideoFx mCurCaptureVideoFx;    private VideoClipFxInfo mVideoClipFxInfo = new VideoClipFxInfo();//    private AlertDialog mFilterDialog;//    private FilterView mFilterView;//    private ArrayList<PushFilterItem> mFilterDataArrayList = new ArrayList<>();    //道具    /**     * 人脸特效是否可用的标识.默认不可用     */    private int mFaceUPropSelPos = 0;    private String mFaceUPropName = "";    private boolean mCanUseARFace = false;    private NvsCaptureVideoFx mARFaceU;//    private AlertDialog mFaceUPropDialog;//    private FaceUPropView mFaceUPropView;//    private ArrayList<PushFilterItem> mPropDataArrayList = new ArrayList<>();    /**     * 是否支持自动聚焦     */    private boolean mSupportAutoFocus = false;    private boolean mDefaultBeautyOpen = false;    private boolean mSharpenDefault = false;    private int mBeautyIndex = 3;//    private SeekBar mDefaultBeautySb;//    private ImageView mDefaultBeautyIv;//    private LinearLayout mStrengthMenuLl;//    private LinearLayout mWhiteningMenuLl;//    private LinearLayout mReddeningMenuLl;    /**     * 美颜开关     */    private boolean mBeautySwitchIsOpend = false;    /**     * 美型开关     */    private boolean mBeautyShapeSwitchIsOpen = false;    /**     * 基础滤镜强度     */    private double mDefaultBeautyIntensity = 1.0;//    private RelativeLayout mStrengthBg;//    private RelativeLayout mWhiteningBg;//    private RelativeLayout mReddeningBg;//    private TextView mStrengthTv;//    private TextView mWhiteningTv;//    private TextView mReddeningTv;    private ByteBuffer rgbaBuffer;    private byte[] rgbaB;    private int imageWidth = 720;    private int imageHeight = 1280;//    private int viewWidth = 720;//    private int viewHeight = 1280;    private int orgViewWidth = 720;    private int orgViewHeight = 1280;    private int viewWidth = 720;    private int viewHeight = 1280;    private int viewPortX = 0;    private int viewPortY = 0;//    private TextView mLogText;    private GLSurfaceView mGLView;    private SurfaceTexture mSurface;    private int mTextureID;    private int mProgram = 0;    private int muMVPMatrixHandle = -1;    private int muSTMatrixHandle = -1;    private int maPositionHandle = -1;    private int maTextureHandle = -1;    private float[] mMVPMatrix = new float[16];    private float[] mSTMatrix = new float[16];    private int[] textures;    private int[] frameBufferBinding;    private int mTextureIDDst;    private HwPublisher mPublisher;    private boolean isConnected;    private final Object writeLock = new Object();    private int mCameraId;    private String recPath = "";    private boolean isRecording;    private boolean isInteractiveLive;    //    private boolean isConnecting;    private int mCurrentDeviceIndex;    private volatile int vFPS;    private volatile int vBitrate;    private volatile int aBitrate;    private long startTouchTime;    private int touchTimes;    private boolean isShowLog;////    /**//     * 判断当前是直播间(主播)还是直播推流界面//     *///    private boolean status;////    /**//     * 直播间名称//     *///    private String roomName;////    /**//     * 用户ID//     *///    private String userId;////    /**//     * 直播间(主播)//     *///    private CircleImageView headIcon;////    /**//     * 直播间名称//     *///    private TextView tvRoomName;////    /**//     * 直播间ID//     *///    private TextView tvRoomId;////    /**//     * 直播间观看人数//     *///    private TextView tvWatcherNumber;////    /**//     * 直播间关闭//     *///    private ImageView ivClose;////    /**//     * 显示弹幕按钮//     *///    private Button ivBarrage;////    /**//     * 弹出发送弹幕对话框的按钮//     *///    private Button ivMessage;////    private Button ivLandScape;////    private Button ivLog;////    private Button ivHD;//    private SendMessageDialog dialog;//    private SelectClarityListDialog clarityListDialog;////    boolean isSelectBarrage = true;//    /**//     * 开启或关闭高清低码//     *///    private Button btnTurnOrOFFLowCode;////    /**//     * 清晰度//     *///    private TextView tvClarity;////    /**//     * 码率//     *///    private TextView tvBitrate;////    /**//     * 帧率//     *///    private TextView tvFrameRate;////    /**//     * 弹幕列表//     *///    private RecyclerView rvBarrageList;////    /**//     * 显示弹幕的适配器//     *///    private BarrageListAdapter adapter;////    /**//     * log的对话框//     *///    private PushLogDialog logDialog;////    /**//     * log//     *///    private ImageView ivPushLog;////    /**//     * 设置//     *///    private ImageView ivPushSetting;////    /**//     * 录制//     *///    private ImageView ivRecording;////    /**//     * 推流//     *///    private ImageView ivPlayer;////    /**//     * 粘贴//     *///    private ImageView ivLink;//    private ImageView ivQrcode;////    /**//     * 录制//     *///    private TextView tvCurrentTime;//    private TextView tvTotalTime;//    private SeekBar progress;//    private List<String> mRecordFileList;    private int totalTime = 0;    private static final int FLOAT_SIZE_BYTES = 4;    private static final int TRIANGLE_VERTICES_DATA_STRIDE_BYTES = 4 * FLOAT_SIZE_BYTES;    private static final int TRIANGLE_VERTICES_DATA_POS_OFFSET = 0;    private static final int TRIANGLE_VERTICES_DATA_UV_OFFSET = 2;    private final float[] mTriangleVerticesData = {            // X, Y, U, V            -1.0f, -1.0f, 0.f, 0.f,            1.0f, -1.0f, 1.f, 0.f,            -1.0f, 1.0f, 0.f, 1.f,            1.0f, 1.0f, 1.f, 1.f,    };    private FloatBuffer mTriangleVertices;    //    private List<LiveMessage> liveMessages;    private final String mVertexShader =            "attribute vec4 aPosition;\n" +                    "attribute vec2 aTextureCoord;\n" +                    "uniform mat4 uMVPMatrix;\n" +                    "uniform mat4 uSTMatrix;\n" +                    "varying vec2 textureCoordinate;\n" +                    "void main()\n" +                    "{\n" +                    "gl_Position = uMVPMatrix * aPosition;\n" +                    "vec4 tex4 = vec4(aTextureCoord.xy, 1.0, 1.0);\n" +                    "textureCoordinate = (uSTMatrix * tex4).xy;\n" +                    "}";    private final String mFragmentShader =            "#extension GL_OES_EGL_image_external : require\n" +                    "precision mediump float;\n" +                    "varying vec2 textureCoordinate;\n" +                    "uniform samplerExternalOES s_texture;\n" +                    "void main() {\n" +                    "gl_FragColor = texture2D(s_texture, textureCoordinate);\n" +                    "}";    private boolean isClick;    private static final int PERMISSION_REQUEST_RECORD_AUDIO = 100;    private String mChannelName;    private String mPublishUrl = "";//    private RecyclerView mSmallView;//    //    private LinearLayout mSelfView;//    private TextView mTvRoomName;////    private ImageView mIvRtmp;////    private HWRtcEngine mRtcEngine;//    private HWLiveTranscoding mLiveTranscoding;////    private Map<Integer, UserInfo> mUserInfo = new HashMap<>();//    private SmallAdapter mSmallAdapter;    // before join channel success, big-uid is zero, after join success big-uid will modify by onJoinChannel-uid    private int mBigUserId = 0;    private SurfaceView mBigView;    //    private MessageAdapter mMessageAdapter;    private ArrayList<String> mMsgList;    private boolean isAccepted;    private AlertDialog alert = null;    private AlertDialog.Builder builder = null;    private int currentVideoUserSize;    private String command_userId;    /**     * 这是用来刷新一些配置信息的UI     */    private static Handler handler = new Handler();    private Context mContext;    private Activity mActivity;    private final MethodChannel methodChannel;    private Application.ActivityLifecycleCallbacks lifecycleCallbacks = new Application.ActivityLifecycleCallbacks() {        @Override        public void onActivityCreated(Activity activity, Bundle savedInstanceState) {            Log.e(TAG, "onActivityCreated");        }        @Override        public void onActivityStarted(Activity activity) {            Log.e(TAG, "onActivityStarted");            onStart();        }        @Override        public void onActivityResumed(Activity activity) {            Log.e(TAG, "onActivityResumed");            onResume();        }        @Override        public void onActivityPaused(Activity activity) {            Log.e(TAG, "onActivityPaused");            onPause();        }        @Override        public void onActivityStopped(Activity activity) {            Log.e(TAG, "onActivityStopped");            onStop();        }        @Override        public void onActivitySaveInstanceState(Activity activity, Bundle outState) {            Log.e(TAG, "onActivitySaveInstanceState");        }        @Override        public void onActivityDestroyed(Activity activity) {            Log.e(TAG, "onActivityDestroyed");        }    };    public HwPushView(BinaryMessenger messenger, Activity activity, int id) {        methodChannel = new MethodChannel(messenger, "com.slh.hw_live/HwPushView_" + id);        methodChannel.setMethodCallHandler(this);        mContext = activity.getApplicationContext();        mActivity = activity;        mActivity.getApplication().registerActivityLifecycleCallbacks(lifecycleCallbacks);        initViews();    }    protected void initViews() {        Log.e(TAG, "initViews");        mGLView = new GLSurfaceView(mContext);        //设置使用openGL ES2.0        mGLView.setEGLContextClientVersion(2);        mGLView.setRenderer(HwPushView.this);        mGLView.setRenderMode(GLSurfaceView.RENDERMODE_WHEN_DIRTY);        //请求推流的权限        //requestPushPermission();        mCameraId = 1;        mPublisher = new HwPublisher(mContext, null, (HwPublisher.HwPreviewCallback) null, true);        mPublisher.setEncodeHandler(new HwEncodeHandler(HwPushView.this));        mPublisher.setRtmpHandler(new RtmpHandler(HwPushView.this));        mPublisher.setRecordHandler(new HwRecordHandler(HwPushView.this));//        mPublisher.setPreviewResolution(960, 540);        mPublisher.setOutputResolution(360, 640);        //mPublisher.setVideoHDMode();        mPublisher.setVgop(15);        mPublisher.setVfps(15);        //mPublisher.startAudioRecord();        isConnected = false;        isRecording = false;//        isConnecting = false;        //mBeautySwitch.setChecked(true);        //initBeautyData();        mStreamingContext = NvsStreamingContext.getInstance();        mStreamingContext.setCaptureDeviceCallback(this);        mStreamingContext.setCaptureRecordingDurationCallback(this);        mStreamingContext.setCaptureRecordingStartedCallback(this);    }    private void initBeautyData() {        mStrengthValue = 0;        mWhiteningValue = 0;        mReddeningValue = 0;        if (mStreamingContext != null) {            NvsFxDescription fxDescription = mStreamingContext.getVideoFxDescription("Beauty");            List<NvsFxDescription.ParamInfoObject> paramInfo = fxDescription.getAllParamsInfo();            for (NvsFxDescription.ParamInfoObject param : paramInfo) {                String paramName = param.getString("paramName");                if ("Strength".equals(paramName)) {                    double maxValue = param.getFloat("floatMaxVal");                    mStrengthValue = param.getFloat("floatDefVal");                    Log.e("mStrengthValue=", mStrengthValue + "");//                    mStrength.setMax((int) (maxValue * 100));//                    mStrength.setProgress((int) (mStrengthValue * 100));                } else if ("Whitening".equals(paramName)) {                    double maxValue = param.getFloat("floatMaxVal");                    mWhiteningValue = param.getFloat("floatDefVal");                    Log.e("mWhiteningValue=", mWhiteningValue + "");//                    mWhitening.setMax((int) (maxValue * 100));//                    mWhitening.setProgress((int) (mWhiteningValue * 100));                } else if ("Reddening".equals(paramName)) {                    double maxValue = param.getFloat("floatMaxVal");                    mReddeningValue = param.getFloat("floatDefVal");                    Log.e("mReddeningValue=", mReddeningValue + "");//                    mReddening.setMax((int) (maxValue * 100));//                    mReddening.setProgress((int) (mReddeningValue * 100));                }            }            //  人脸特效是否可用            if (mCanUseARFace) {                mARFaceU = mStreamingContext.appendBuiltinCaptureVideoFx("Face Effect");                if (mARFaceU != null) {                    mARFaceU.setStringVal("Beautification Package", "assets:/NvBeautification.asset");                    mARFaceU.setMenuVal("Face Type", "");                    mARFaceU.setFloatVal("Face Shape Level", 0);                    resetBeautyShapeDefaultValue();                }            }        }    }    private void startPublish(String url) {        if (!NetworkUtils.isConnected()) {            showToast("当前网络不可用，请检查你的网络设置");            return;        }        if (TextUtils.isEmpty(url)) {            return;        }        if (!isConnected) {            isConnected = true;            rtmpUrl = url;            if (mPublisher != null) {                mPublisher.startAudioRecord();                mPublisher.startPublish(rtmpUrl);            }        }    }    private void stopPublish() {        isConnected = false;        if (mPublisher != null) {            mPublisher.stopAudioRecord();            mPublisher.stopPublish();        }    }    //关闭直播间    private void close() {        if (mPublisher != null) {            mPublisher.stopAudioRecord();            mPublisher.stopRecord();            mPublisher.stopPublish();            mPublisher = null;        }    }    // /*变焦调节*/ //设置缩放比例    private void setZoom(int progress) {        //设置缩放比例        mStreamingContext.setZoom(progress);    }    // //设置曝光补偿    private void setExposureCompensation(int progress) {        //设置曝光补偿        mStreamingContext.setExposureCompensation(progress + mMinExpose);    }    //切换摄像头    private void cameraSwitch() {        if (mIsSwitchingCamera) {            return;        }        if (mCurrentDeviceIndex == 0) {            mCurrentDeviceIndex = 1;        } else {            mCurrentDeviceIndex = 0;        }        mIsSwitchingCamera = true;        startCapturePreview(true);    }    //切换软硬编码    private void encoderSwitch() {        Log.e(TAG, "mSwitchEncoderLayout.setOnClickListener ");        if (mPublisher.isSoftEncoder()) {            Toast.makeText(mContext, "编码 状态：" + "硬编码", Toast.LENGTH_SHORT).show();            mPublisher.switchToHardEncoder();        } else {            Toast.makeText(mContext, "编码 状态：" + "软编码", Toast.LENGTH_SHORT).show();            mPublisher.switchToSoftEncoder();        }    }    /*闪光灯*/    private void flashLightSwitch() {        if (mStreamingContext.isFlashOn()) {            mStreamingContext.toggleFlash(false);        } else {            mStreamingContext.toggleFlash(true);        }    }    //    /*录制*///        ivRecording.setOnClickListener(new View.OnClickListener() {//        @Override//        public void onClick(View v) {//            Log.e(TAG, "mOpenRecordLayout.setOnClickListener ");//            if (!isRecording) {//                isRecording = true;//                ivRecording.setImageResource(R.mipmap.icon_push_recording_focus);//                findViewById(R.id.cl_record_progress).setVisibility(View.VISIBLE);//                Toast.makeText(HwPushView.this, "录制 状态：" + "开始录制", Toast.LENGTH_SHORT).show();//                mStreamingContext.startRecording(recPath);//                mRecordFileList.add(recPath);//            } else {//                isRecording = false;//                ivRecording.setImageResource(R.mipmap.icon_recording_normal);//                showPreviewDialog();//                Toast.makeText(HwPushView.this, "编码 状态：" + "停止录制", Toast.LENGTH_SHORT).show();//                mStreamingContext.stopRecording();//            }//        }//    });////    //取消录制//    findViewById(R.id.tv_record_cancel).setOnClickListener(new View.OnClickListener() {//        @Override//        public void onClick(View v) {//            isRecording = false;//            ivRecording.setImageResource(R.mipmap.icon_recording_normal);//            findViewById(R.id.cl_record_progress).setVisibility(View.GONE);//        }//    });    //  /*基础美颜*/    private void beautySwitch() {//        mDefaultBeautyOpen = !mDefaultBeautyOpen;//        if(mBeautyFx == null){//            mBeautyFx = mStreamingContext.appendBeautyCaptureVideoFx();//        }//        if (mBeautyFx.getBooleanVal("Default Beauty Enabled")) {//            mBeautyFx.setBooleanVal("Default Beauty Enabled", false);////        } else {//            mBeautyFx.setBooleanVal("Default Beauty Enabled", true);//        }        if (mDefaultBeautyOpen) {            mDefaultBeautyOpen = false;            mSharpenDefault = false;            // 重置索引位置            mBeautyIndex = 3;            removeFilterFxByName("Beauty");            mBeautyFx = null;        } else {            if(mBeautyFx == null){                mBeautyFx = mStreamingContext.appendBeautyCaptureVideoFx();            }            mDefaultBeautyOpen = true;            mSharpenDefault = true;            //添加美颜采集特效            mBeautyFx.setBooleanVal("Default Sharpen Enabled", mSharpenDefault);            //设置美颜强度值//            mBeautyFx.setFloatVal("Strength", mStrengthValue);//            mBeautyFx.setFloatVal("Whitening", mWhiteningValue);//            mBeautyFx.setFloatVal("Reddening", mReddeningValue);            mBeautyFx.setFloatVal("Strength", 0.5);            mBeautyFx.setFloatVal("Whitening", 0.5);            mBeautyFx.setFloatVal("Reddening", 0.5);            // 基础滤镜强度            mDefaultBeautyIntensity = mBeautyFx.getFloatVal("Default Intensity");        }    }    // /*锐化关状态——点击*/    private void s() {        mBeautyFx.setBooleanVal("Default Sharpen Enabled", true);        mBeautyFx.setBooleanVal("Default Sharpen Enabled", false);    }    /**     * 获取当前的时间     *     * @return 转成时分秒     */    private String getCurrentTime() {        SimpleDateFormat formatter = new SimpleDateFormat("HH:mm:ss", Locale.CHINA);        //获取当前时间        Date curDate = new Date(System.currentTimeMillis());        return formatter.format(curDate);    }    private void resetBeautyShapeDefaultValue() {        mARFaceU.setFloatVal(BEAUTY_SHAPE_EYE_ENLARGING, 0f);        mARFaceU.setFloatVal(BEAUTY_SHAPE_CHECK_THINNING, 0f);        mARFaceU.setFloatVal(BEAUTY_SHAPE_INTENSITY_FORHEAD, NORMAL_VELUE_INTENSITY_FORHEAD);        mARFaceU.setFloatVal(BEAUTY_SHAPE_INTENSITY_CHIN, NORMAL_VELUE_INTENSITY_CHIN);        mARFaceU.setFloatVal(BEAUTY_SHAPE_INTENSITY_NOSE, 0f);        mARFaceU.setFloatVal(BEAUTY_SHAPE_INTENSITY_MOUTH, NORMAL_VELUE_INTENSITY_MOUTH);    }    private void removeAllFilterFx() {        List<Integer> removeList = new ArrayList<>();        for (int i = 0; i < mStreamingContext.getCaptureVideoFxCount(); i++) {            NvsCaptureVideoFx fx = mStreamingContext.getCaptureVideoFxByIndex(i);            if (fx == null) {                continue;            }            String name = fx.getBuiltinCaptureVideoFxName();            if (name != null && !name.equals("Beauty") && !name.equals("Face Effect")) {                removeList.add(i);                Log.e("===>", "fx name: " + name);            }        }        if (!removeList.isEmpty()) {            for (int i = 0; i < removeList.size(); i++) {                mStreamingContext.removeCaptureVideoFx(removeList.get(i));            }        }    }    private boolean removeFilterFxByName(String name) {        for (int i = 0; i < mStreamingContext.getCaptureVideoFxCount(); i++) {            NvsCaptureVideoFx fx = mStreamingContext.getCaptureVideoFxByIndex(i);            if (fx.getDescription().getName().equals(name)) {                mStreamingContext.removeCaptureVideoFx(i);                return true;            }        }        return false;    }//    private void startPermissionsActivity(int code, String... permission) {//        PermissionsActivity.startActivityForResult(this, code, permission);//    }    private int getCodeInPermission(String permission) {        int code = 0;        switch (permission) {            case Manifest.permission.CAMERA:                code = REQUEST_CAMERA_PERMISSION_CODE;                break;            case Manifest.permission.RECORD_AUDIO:                code = REQUEST_RECORD_AUDIO_PERMISSION_CODE;                break;            case Manifest.permission.WRITE_EXTERNAL_STORAGE:                code = REQUEST_WRITE_EXTERNAL_STORAGE_PERMISSION_CODE;                break;            default:                break;        }        return code;    }    /**     * 获取当前引擎状态     *     * @return 当前状态     */    private int getCurrentEngineState() {        return mStreamingContext.getStreamingEngineState();    }    private void updateSettingsWithCapability(int deviceIndex) {        //获取采集设备能力描述对象，设置自动聚焦，曝光补偿，缩放        mCapability = mStreamingContext.getCaptureDeviceCapability(deviceIndex);        if (null == mCapability) {            return;        }        //是否支持闪光灯        if (mCapability.supportFlash) {        }        mSupportAutoFocus = mCapability.supportAutoFocus;        // 是否支持缩放        if (mCapability.supportZoom) {            mZoomValue = mCapability.maxZoom;        } else {            Log.e(TAG, "该设备不支持缩放");        }        // 是否支持曝光补偿        if (mCapability.supportExposureCompensation) {            mMinExpose = mCapability.minExposureCompensation;        }    }    @Override    public void onCaptureDeviceCapsReady(int captureDeviceIndex) {        if (mCurrentDeviceIndex != captureDeviceIndex) {            return;        }        updateSettingsWithCapability(captureDeviceIndex);    }    @Override    public void onCaptureDevicePreviewResolutionReady(int i) {        NvsSize size = mStreamingContext.getCapturePreviewVideoSize(i);        imageWidth = size.width;        imageHeight = size.height;        int ratio = (viewWidth * imageHeight) / (viewHeight * imageWidth);        if (ratio <= 0) {            viewWidth = viewHeight * imageWidth / imageHeight;            viewPortX = -(viewWidth - orgViewWidth) / 2;        } else {            viewHeight = viewWidth * imageHeight / imageWidth;            viewPortY = -(viewHeight - orgViewHeight) / 2;        }        Log.e(TAG, "size: " + size.width + ", " + size.height);    }    @Override    public void onCaptureDevicePreviewStarted(int i) {        mIsSwitchingCamera = false;        Log.e(TAG, "onCaptureDevicePreviewStarted ");    }    @Override    public void onCaptureDeviceError(int i, int i1) {    }    @Override    public void onCaptureDeviceStopped(int i) {    }    @Override    public void onCaptureDeviceAutoFocusComplete(int i, boolean b) {    }    /**     * 录制完成的回调     *     * @param i     */    @Override    public void onCaptureRecordingFinished(int i) {        // 保存到媒体库//        if (mRecordFileList != null && !mRecordFileList.isEmpty()) {//            for (String path : mRecordFileList) {//                if (path == null) {//                    continue;//                }//                if (path.endsWith(".mp4")) {//                    MediaScannerUtil.scanFile(path, "video/mp4");//                } else if (path.endsWith(".jpg")) {//                    MediaScannerUtil.scanFile(path, "image/jpg");//                }//            }//        }    }    /**     * 录制失败     */    @Override    public void onCaptureRecordingError(int i) {        Log.e(TAG, String.valueOf(i));    }    /**     * 正在录制的回调     *     * @param l 正在录制的时长(毫秒)     */    @Override    public void onCaptureRecordingDuration(int i, long l) {//        String time = "01:45:00";//       // tvTotalTime.setText(String.format("/ %s", time));//        totalTime = TimeFormatUtil.formatString2Us(time);//       // progress.setMax(totalTime);//        int second = (int) (l * 0.000001);//        if (second <= totalTime) {//         //   tvCurrentTime.setText(TimeFormatUtil.formatUsToString2(l));//          //  progress.setProgress(second);//        }//        if (progress.getProgress() == progress.getMax()) {//            mStreamingContext.stopRecording();//          //  showPreviewDialog();//        }    }    /**     * 开始录制     */    @Override    public void onCaptureRecordingStarted(int i) {        Log.d(TAG, String.valueOf(i));    }    protected void onResume() {        Log.e(TAG, "onResume");        if (mPermissionsChecker == null) {            mPermissionsChecker = new PermissionsChecker(mActivity);        }        mGLView.onResume();        if (mStreamingContext != null) {            mStreamingContext.resumeRecording();        }    }    protected void onPause() {        Log.e(TAG, "onPause");        if (mPublisher != null) {            mPublisher.pauseRecord();        }        if (mStreamingContext != null) {            mStreamingContext.connectCapturePreviewWithSurfaceTexture(null);            mStreamingContext.stop();            mStreamingContext.pauseRecording();        }        if (mSurface != null) {            mSurface.setOnFrameAvailableListener(null);        }        mGLView.onPause();        isPause = true;    }    protected void onStart() {        isPause = false;    }    protected void onStop() {        Log.e(TAG, "onStop");        if (mStreamingContext != null) {            mStreamingContext.stop();            mStreamingContext.stopRecording();        }    }    @Override    public void onFrameAvailable(final SurfaceTexture surfaceTexture) {//        Log.e(TAG, "onFrameAvailable");        if (isPause) {            return;        }        mGLView.queueEvent(                new Runnable() {                    @Override                    public void run() {                        try {                            surfaceTexture.updateTexImage();                            surfaceTexture.getTransformMatrix(mSTMatrix);                            downloadImageFromTexture2();                        } catch (Exception e) {                            Log.e(TAG, e.getMessage());                        }                    }                });        mGLView.requestRender();    }    @Override    public void onSurfaceCreated(GL10 gl10, EGLConfig eglConfig) {        Log.e(TAG, "onSurfaceCreated");        handler.removeCallbacksAndMessages(null);        Matrix.setIdentityM(mMVPMatrix, 0);        mTriangleVertices = ByteBuffer.allocateDirect(                mTriangleVerticesData.length * FLOAT_SIZE_BYTES)                .order(ByteOrder.nativeOrder()).asFloatBuffer();        mTriangleVertices.put(mTriangleVerticesData).position(0);        mProgram = createProgram(mVertexShader, mFragmentShader);        if (mProgram == 0) {            return;        }        maPositionHandle = GLES20.glGetAttribLocation(mProgram, "aPosition");        checkGLError("glGetAttribLocation aPosition");        if (maPositionHandle == -1) {            return;        }        maTextureHandle = GLES20.glGetAttribLocation(mProgram, "aTextureCoord");        checkGLError("glGetAttribLocation aTextureCoord");        if (maTextureHandle == -1) {            return;        }        muMVPMatrixHandle = GLES20.glGetUniformLocation(mProgram, "uMVPMatrix");        checkGLError("glGetUniformLocation uMVPMatrix");        if (muMVPMatrixHandle == -1) {            return;        }        muSTMatrixHandle = GLES20.glGetUniformLocation(mProgram, "uSTMatrix");        checkGLError("glGetUniformLocation uSTMatrix");        if (muSTMatrixHandle == -1) {            return;        }        textures = new int[2];        GLES20.glGenTextures(2, textures, 0);        if (textures[0] == 0 || textures[1] == 0) {            return;        }        mTextureID = textures[0];        mTextureIDDst = textures[1];        GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, mTextureID);        checkGLError("glBindTexture");        GLES20.glTexParameterf(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_MIN_FILTER, GLES20.GL_NEAREST);        GLES20.glTexParameterf(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_MAG_FILTER, GLES20.GL_NEAREST);        mSurface = new SurfaceTexture(mTextureID);        mSurface.setOnFrameAvailableListener(this);        frameBufferBinding = new int[1];        GLES20.glGenFramebuffers(1, frameBufferBinding, 0);        checkGLError("DownloadImageFromTexture");        handler.post(new Runnable() {            @Override            public void run() {                if (mPermissionGranted) {                    startCapturePreview(mCameraId);                }            }        });    }    private void startCapturePreview(int id) {        if (mStreamingContext == null) {            Log.e(TAG, "mStreamingContext is null!");            return;        }        mStreamingContext.connectCapturePreviewWithSurfaceTexture(mSurface);        mStreamingContext.setCaptureDeviceCallback(this);        mStreamingContext.setCaptureFps(15);//        if(mUseBeauty) {//            NvsCaptureVideoFx fx = mStreamingContext.appendBeautyCaptureVideoFx();     //添加美颜采集特效//            fx.setFloatVal("Strength", 0.5d);//设置美颜强度值(0-1)//            fx.setFloatVal("Whitening", 0.5d);//            fx.setFloatVal("Reddening", 0.5d);//        }        if (getCurrentEngineState() != NvsStreamingContext.STREAMING_ENGINE_STATE_CAPTUREPREVIEW) {            if (!mStreamingContext.startCapturePreview(id, NvsStreamingContext.VIDEO_CAPTURE_RESOLUTION_GRADE_HIGH, NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_DONT_USE_SYSTEM_RECORDER |                    NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_CAPTURE_BUDDY_HOST_VIDEO_FRAME                    | NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_STRICT_PREVIEW_VIDEO_SIZE                    | NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_DONT_CAPTURE_AUDIO, null)) {                Log.e(TAG, "Failed to start capture preview!");            }        }        mCurrentDeviceIndex = id % 2;    }    /**     * 判断当前引擎状态是否为采集预览状态     *     * @param deviceChanged 是否改变     */    private boolean startCapturePreview(boolean deviceChanged) {        // 判断当前引擎状态是否为采集预览状态        int captureResolutionGrade = ParameterSettingValues.instance().getCaptureResolutionGrade();        if (deviceChanged || getCurrentEngineState() != NvsStreamingContext.STREAMING_ENGINE_STATE_CAPTUREPREVIEW) {            mSupportAutoFocus = false;            if (!mStreamingContext.startCapturePreview(mCurrentDeviceIndex,                    captureResolutionGrade,                    NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_DONT_USE_SYSTEM_RECORDER |                            NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_CAPTURE_BUDDY_HOST_VIDEO_FRAME                            | NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_STRICT_PREVIEW_VIDEO_SIZE                            | NvsStreamingContext.STREAMING_ENGINE_CAPTURE_FLAG_DONT_CAPTURE_AUDIO, null)) {                Log.e(TAG, "Failed to start capture preview!");                return false;            }        }        return true;    }    @Override    public void onSurfaceChanged(GL10 gl10, int width, int height) {        orgViewWidth = width;        orgViewHeight = height;        viewWidth = orgViewWidth;        viewHeight = orgViewHeight;        Log.e(TAG, "onSurfaceChanged");    }    @Override    public void onDrawFrame(GL10 gl10) {        draw(viewPortX, viewPortY, viewWidth, viewHeight);//        downloadImageFromTexture2();    }    private void draw(int x, int y, int width, int height) {        GLES20.glUseProgram(mProgram);        GLES20.glClearColor(1, 1, 1, 1);        GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT);//        GLES20.glViewport(0, 0, width, height);//        GLES20.glViewport(viewPortX, viewPortY, width, height);//zhang        GLES20.glViewport(x, y, width, height);        GLES20.glActiveTexture(GLES20.GL_TEXTURE0);        GLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, mTextureID);        GLES20.glTexParameterf(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_MIN_FILTER, GLES20.GL_NEAREST);        GLES20.glTexParameterf(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, GLES20.GL_TEXTURE_MAG_FILTER, GLES20.GL_NEAREST);        mTriangleVertices.position(TRIANGLE_VERTICES_DATA_POS_OFFSET);        GLES20.glVertexAttribPointer(maPositionHandle, 2, GLES20.GL_FLOAT, false, TRIANGLE_VERTICES_DATA_STRIDE_BYTES, mTriangleVertices);        GLES20.glEnableVertexAttribArray(maPositionHandle);        mTriangleVertices.position(TRIANGLE_VERTICES_DATA_UV_OFFSET);        GLES20.glVertexAttribPointer(maTextureHandle, 2, GLES20.GL_FLOAT, false, TRIANGLE_VERTICES_DATA_STRIDE_BYTES, mTriangleVertices);        GLES20.glEnableVertexAttribArray(maTextureHandle);        GLES20.glUniformMatrix4fv(muMVPMatrixHandle, 1, false, mMVPMatrix, 0);        GLES20.glUniformMatrix4fv(muSTMatrixHandle, 1, false, mSTMatrix, 0);        GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP, 0, 4);        checkGLError("DownloadImageFromTexture");        GLES20.glDisableVertexAttribArray(maPositionHandle);        GLES20.glDisableVertexAttribArray(maTextureHandle);    }    private int loadShader(int shaderType, String source) {        int shader = GLES20.glCreateShader(shaderType);        if (shader != 0) {            GLES20.glShaderSource(shader, source);            GLES20.glCompileShader(shader);            int[] compiled = new int[1];            GLES20.glGetShaderiv(shader, GLES20.GL_COMPILE_STATUS, compiled, 0);            if (compiled[0] == 0) {                Log.e(TAG, "Could not compile shader " + shaderType + ":");                Log.e(TAG, GLES20.glGetShaderInfoLog(shader));                GLES20.glDeleteShader(shader);                shader = 0;            }        }        return shader;    }    private int createProgram(String vertexSource, String fragmentSource) {        int vertexShader = loadShader(GLES20.GL_VERTEX_SHADER, vertexSource);        if (vertexShader == 0) {            return 0;        }        int pixelShader = loadShader(GLES20.GL_FRAGMENT_SHADER, fragmentSource);        if (pixelShader == 0) {            return 0;        }        int program = GLES20.glCreateProgram();        if (program != 0) {            GLES20.glAttachShader(program, vertexShader);            checkGLError("glAttachShader");            GLES20.glAttachShader(program, pixelShader);            checkGLError("glAttachShader");            GLES20.glLinkProgram(program);            int[] linkStatus = new int[1];            GLES20.glGetProgramiv(program, GLES20.GL_LINK_STATUS, linkStatus, 0);            if (linkStatus[0] != GLES20.GL_TRUE) {                Log.e(TAG, "Could not link program: ");                Log.e(TAG, GLES20.glGetProgramInfoLog(program));                GLES20.glDeleteProgram(program);                program = 0;            }        }        return program;    }    private void checkGLError(String op) {        int error;        if ((error = GLES20.glGetError()) != GLES20.GL_NO_ERROR) {            Log.e(TAG, op + ": glError " + error);        }    }    private void downloadImageFromTexture2() {        GLES20.glBindTexture(GLES20.GL_TEXTURE_2D, mTextureIDDst);        GLES20.glTexImage2D(GLES20.GL_TEXTURE_2D, 0, GLES20.GL_RGBA, imageWidth, imageHeight, 0, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, null);        GLES20.glTexParameteri(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MIN_FILTER, GLES20.GL_NEAREST);        GLES20.glTexParameteri(GLES20.GL_TEXTURE_2D, GLES20.GL_TEXTURE_MAG_FILTER, GLES20.GL_NEAREST);        GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, frameBufferBinding[0]);        GLES20.glFramebufferTexture2D(GLES20.GL_FRAMEBUFFER, GLES20.GL_COLOR_ATTACHMENT0, GLES20.GL_TEXTURE_2D, mTextureIDDst, 0);        checkGLError("DownloadImageFromTexture");//        draw(imageWidth, imageHeight);        draw(0, 0, imageWidth, imageHeight);        if (rgbaBuffer == null) {            rgbaBuffer = ByteBuffer.allocate(imageWidth * imageHeight * 4);        }        rgbaBuffer.position(0);        // Download image//        GLES20.glReadPixels(viewPortX, viewPortY, imageWidth, imageHeight, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, rgbaBuffer);//zhang        GLES20.glReadPixels(0, 0, imageWidth, imageHeight, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, rgbaBuffer);        checkGLError("DownloadImageFromTexture");        GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, 0);        synchronized (writeLock) {            if ((mPublisher != null) && (!isInteractiveLive) && isConnected) {                com.huawei.publishsdk.HWVideoFrame videoFrame = new com.huawei.publishsdk.HWVideoFrame();                videoFrame.data = rgbaBuffer.array();                videoFrame.width = imageWidth;                videoFrame.height = imageHeight;                videoFrame.type = RGBA;                videoFrame.rotation = 0;                mPublisher.pushExternVideoFrame(videoFrame);            } else if (isInteractiveLive) {//                if (mRtcEngine != null) {////                        Log.e(TAG, "DownloadImageFromTexture2 pushExternalVideoFrame");//                    HWVideoFrame VideoFrame = new HWVideoFrame();//                    VideoFrame.buf = rgbaBuffer.array();//                    VideoFrame.format = FORMAT_RGBA;//                    VideoFrame.stride = 720;//                    VideoFrame.height = 1280;//                    VideoFrame.rotation = 180;//                    VideoFrame.timeStamp = System.currentTimeMillis();//                    boolean ret = mRtcEngine.pushExternalVideoFrame(VideoFrame);//                }            }        }    }    /**     * 弹出Toast提示     *     * @param message 提示信息     */    private void showToast(String message) {        Toast.makeText(mContext, message, Toast.LENGTH_SHORT).show();    }    @Override    public void onNetworkWeak() {        Log.e(TAG, "onNetworkWeak");    }    @Override    public void onNetworkResume() {        Log.e(TAG, "onNetworkResume");    }    @Override    public void onEncodeIllegalArgumentException(IllegalArgumentException e) {        Log.e(TAG, "onEncodeIllegalArgumentException");    }    @Override    public void onRtmpConnecting(String msg) {        Log.e(TAG, "onRtmpConnecting");        showToast("正在推流");    }    @Override    public void onRtmpConnected(String msg) {        Log.e(TAG, "onRtmpConnected");        isConnected = true;        showToast("推流成功");    }    @Override    public void onRtmpVideoStreaming() {//        Log.e(TAG,"onRtmpVideoStreaming");    }    @Override    public void onRtmpAudioStreaming() {//        Log.e(TAG,"onRtmpAudioStreaming");    }    @Override    public void onRtmpStopped() {        Log.e(TAG, "onRtmpStopped");        showToast("推流停止");    }    @Override    public void onRtmpDisconnected() {        Log.e(TAG, "onRtmpDisconnected");        isConnected = false;        showToast("推流断开");        if ((!isInteractiveLive) && (isAccepted)) {            isInteractiveLive = true;            Log.e(TAG, "onRtmpDisconnected initEngine ");            isAccepted = false;//            if(mRtcEngine!=null)//                mRtcEngine.addPublishStreamUrl(mSeverPublishUrl, true);            mGLView.setZOrderMediaOverlay(true);        }    }    /**     * 推流的帧率     *     * @param fps 帧率     */    @Override    public void onRtmpVideoFpsChanged(double fps) {        vFPS = (int) fps;    }    /**     * 推流的码率     *     * @param bitrate 码率     */    @Override    public void onRtmpVideoBitrateChanged(double bitrate) {        vBitrate = (int) (bitrate / 1000);    }    /**     * 推流的音频码率     *     * @param bitrate 音频码率     */    @Override    public void onRtmpAudioBitrateChanged(double bitrate) {        aBitrate = (int) (bitrate / 1000);    }    @Override    public void onRtmpSocketException(SocketException e) {        handleException(e);    }    @Override    public void onRtmpIOException(IOException e) {        handleException(e);    }    @Override    public void onRtmpIllegalArgumentException(IllegalArgumentException e) {        handleException(e);    }    @Override    public void onRtmpIllegalStateException(IllegalStateException e) {        handleException(e);    }    @Override    public void onRecordPause() {    }    @Override    public void onRecordResume() {    }    @Override    public void onRecordStarted(String s) {    }    @Override    public void onRecordFinished(String s) {    }    @Override    public void onRecordIllegalArgumentException(IllegalArgumentException e) {    }    @Override    public void onRecordIOException(IOException e) {    }    private void handleException(Exception e) {        showToast("推流失败:" + e.toString());        try {            Toast.makeText(mContext, e.getMessage(), Toast.LENGTH_SHORT).show();            isConnected = false;            if (mPublisher != null) {                mPublisher.stopPublish();                mPublisher.stopAudioRecord();                mPublisher.stopRecord();            }        } catch (Exception e1) {            //        }        handlerConnectError.sendEmptyMessage(0);    }    //断网自动重连    int delayTime = 1;    Thread reconnectworker = null;    private Handler handlerConnectError = new Handler() {        public void handleMessage(android.os.Message msg) {            switch (msg.what) {                case 0:                    if (reconnectworker != null) {                        reconnectworker.interrupt();                        reconnectworker = null;                    }                    // 移除所有的msg.what为0等消息，保证只有一个循环消息队列再跑                    handlerConnectError.removeMessages(0);                    reconnectworker = new Thread(new Runnable() {                        @Override                        public void run() {                            try {                                Thread.sleep(delayTime * 100);                            } catch (InterruptedException e1) {                                e1.printStackTrace();                            }                            // app的功能逻辑处理                            Log.e(TAG, "handleException isAvailableByPing: " + isAvailableByPing());                            if (isAvailableByPing()) {                                Log.e(TAG, "handleMessage clicked! ");                                mActivity.runOnUiThread(                                        new Runnable() {                                            @Override                                            public void run() {                                                if (isConnected == false) {                                                    startPublish(rtmpUrl);                                                }                                            }                                        }                                );                            } else {                                handlerConnectError.sendEmptyMessage(0);                            }                            delayTime++;                            if (delayTime > 10) {                                handlerConnectError.sendEmptyMessage(1);                            }                        }                    });                    reconnectworker.start();                    // 再次发出msg，循环更新//                    handlerConnectError.sendEmptyMessageDelayed(0, delayTime*1000);                    break;                case 1:                    // 直接移除，定时器停止                    handlerConnectError.removeMessages(0);                    if (reconnectworker != null) {                        reconnectworker.interrupt();                        reconnectworker = null;                    }                    break;                default:                    break;            }        }        ;    };    @Override    public View getView() {        return mGLView;    }    @Override    public void dispose() {        mActivity.getApplication().unregisterActivityLifecycleCallbacks(lifecycleCallbacks);        Log.e(TAG, "dispose");        methodChannel.setMethodCallHandler(null);        if (isConnected && (mPublisher != null)) {            isConnected = false;            mPublisher.stopPublish();            mPublisher.stopRecord();            mPublisher.stopAudioRecord();            mPublisher.stopCamera();            mPublisher.release();            mPublisher = null;        }        if (mStreamingContext != null) {            mStreamingContext.setCaptureDeviceCallback(null);            mStreamingContext.setCapturedVideoFrameGrabberCallback(null);            mStreamingContext.stopRecording();            NvsStreamingContext.close();        }    }    @Override    public void onMethodCall(MethodCall methodCall, MethodChannel.Result result) {        Map<String, Object> request = methodCall.arguments();        if (methodCall.method.equals("startPublish")) {            startPublish(request.get("url").toString());            result.success(true);        } else if (methodCall.method.equals("cameraSwitch")) {            cameraSwitch();            result.success(true);        } else if (methodCall.method.equals("stopPublish")) {            stopPublish();            result.success(true);        } else if (methodCall.method.equals("flashLightSwitch")) {            flashLightSwitch();            result.success(true);        } else if (methodCall.method.equals("beautySwitch")) {            beautySwitch();            result.success(true);        } else if (methodCall.method.equals("close")) {            close();            result.success(true);        } else {            result.notImplemented();        }    }}